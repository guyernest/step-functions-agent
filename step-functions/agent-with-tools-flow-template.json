{
  "Comment": "AI Agent Implementation",
  "QueryLanguage": "JSONata",
  "StartAt": "Call LLM",
  "States": {
    "Call LLM": {
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke",
      "Retry": [
        {
          "ErrorEquals": [
            "Lambda.ServiceException",
            "Lambda.AWSLambdaException",
            "Lambda.SdkClientException",
            "Lambda.TooManyRequestsException"
          ],
          "IntervalSeconds": 1,
          "MaxAttempts": 3,
          "BackoffRate": 2,
          "JitterStrategy": "FULL"
        }
      ],
      "Next": "Is done?",
      "Arguments": {
        "Payload": {
          "system": "You are an expert business analyst with deep knowledge of SQL and visualization code in Python. Your job is to help users understand and analyze their internal baseball data. You have access to a set of tools, but only use them when needed. You also have access to a tool that allows execution of python code. Use it to generate the visualizations in your analysis. - the python code runs in jupyter notebook. - every time you call `execute_python` tool, the python code is executed in a separate cell. it's okay to multiple calls to `execute_python`. - display visualizations using matplotlib directly in the notebook. don't worry about saving the visualizations to a file. - you can run any python code you want, everything is running in a secure sandbox environment.",
          "messages": "{% $states.input.messages %}",
          "tools": []
        },
        "FunctionName": "arn:aws:lambda:<region>:<account>:function:CallLLM:$LATEST"
      },
      "Comment": "The main call to the LLM. Returns the list of messages with the current call at the end, and metadata of the last call.",
      "Output": {
        "messages": "{% $states.result.Payload.body.messages%}",
        "metadata": "{% $states.result.Payload.body.metadata%}"
      },
      "Assign": {
        "messages": "{% $states.result.Payload.body.messages%}"
      }
    },
    "Is done?": {
      "Type": "Choice",
      "Default": "For each tool use",
      "Choices": [
        {
          "Condition": "{% $states.input.metadata.stop_reason in [\"end_turn\", \"stop\"] %}",
          "Next": "Prepare Output"
        },
        {
          "Condition": "{% $states.input.messages[-1].**.name = \"print_output\" %}",
          "Next": "Print Output"
        }
      ],
      "Comment": "Checks if the 'stop_reason' from the LLM was a request for a 'tool_use' (except for print_output), and if so, route it to the tools path, otherwise reply to the user."
    },
    "Prepare Output": {
      "Type": "Pass",
      "End": true,
      "Output": {
        "messages": "{% $states.input.messages %}",
        "output": {
          "answer": "{% $states.input.messages[-1].content[0].text %}"
        }
      },
      "Comment": "Extracts the relevant information from the flow, including all the message flow, the textual answer from the last message, and the chart that was generated during the flow."
    },
    "For each tool use": {
      "Type": "Map",
      "Items": "{% ($provider = \"anthropic\" ? $states.input.messages[-1].content : $states.input.messages[-1].tool_calls) %}",
      "ItemProcessor": {
        "ProcessorConfig": {
          "Mode": "INLINE"
        },
        "StartAt": "Which Tool to Use?",
        "States": {
          "Which Tool to Use?": {
            "Type": "Choice",
            "Choices": [
              {
                "Next": "Get DB Schema",
                "Condition": "{% ($states.input.type = \"tool_use\") and ($states.input.name = \"get_db_schema\") %}"
              },
              {
                "Next": "Execute SQL Query",
                "Condition": "{% ($states.input.type = \"tool_use\") and ($states.input.name = \"execute_sql_query\") %}"
              },
              {
                "Next": "execute_python",
                "Condition": "{% $states.input.type = \"tool_use\" and $states.input.name = \"execute_python\" %}"
              }
            ],
            "Default": "No Tool to Use (ignore)",
            "Comment": "Check if the request is for 'tool_use' and then to which of the available tools to send it."
          },
          "No Tool to Use (ignore)": {
            "Type": "Pass",
            "End": true,
            "Output": {},
            "Comment": "This path handles the text replies of the LLM that decribe its thinking and don't require any tool to use."
          }
        }
      },
      "Next": "Append Map to Messages",
      "Output": {
        "messages": "{% $provider = \"anthropic\" ? $append($states.input.messages, [ {  \"role\": \"user\",    \"content\": [$filter($states.result,function($v) { $v != {} })] } ] ) : $append($states.input.messages, [$filter($states.result,function($v) { $v != {} })]) %}"
      },
      "Comment": "The reply of the LLM can include one or more 'tool_use' request, and we can apply them in parallel."
    },
    "Append Map to Messages": {
      "Type": "Pass",
      "Next": "Call LLM",
      "Comment": "Gather the replies of the different tools and call the LLM to continue the agent flow."
    },
    "Print Output": {
      "Type": "Pass",
      "End": true,
      "Output": {
        "messages": "{% $messages %}",
        "output": "{% $provider = \"anthropic\" ? $states.input.messages[-1].content[**.name = \"print_output\"].input : $parse($states.input.messages[-1].tool_calls[**.name = \"print_output\"].function.arguments) %}"
      }
    }
  }
}